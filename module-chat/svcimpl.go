/**
* Generated by go-doudou v2.5.9.
* You can edit it as your need.
 */
package service

import (
	"context"
	"encoding/json"
	"fmt"
	"go-doudou-rag/module-chat/config"
	"go-doudou-rag/module-chat/contextutil"
	"go-doudou-rag/module-chat/dto"
	know "go-doudou-rag/module-knowledge"
	kdto "go-doudou-rag/module-knowledge/dto"
	"net/http"
	"os"

	"github.com/unionj-cloud/toolkit/stringutils"

	"github.com/ascarter/requestid"
	"github.com/samber/do"
	"github.com/samber/lo"
	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/openai"
	"github.com/unionj-cloud/toolkit/zlogger"
)

var _ ModuleChat = (*ModuleChatImpl)(nil)

type ModuleChatImpl struct {
	conf *config.Config
}

func NewModuleChat(conf *config.Config) *ModuleChatImpl {
	return &ModuleChatImpl{
		conf: conf,
	}
}

func (receiver *ModuleChatImpl) Chat(ctx context.Context, req dto.ChatRequest) (err error) {
	w, _ := contextutil.ResponseWriterFromContext(ctx)
	requestID, _ := requestid.FromContext(ctx)

	// Set headers before any potential error responses
	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("Transfer-Encoding", "chunked")

	flusher, ok := w.(http.Flusher)
	if !ok {
		zlogger.Error().Msgf("Streaming not supported, requestId: %s", requestID)
		chunk := dto.ChatResponse{
			Content:   "Streaming unsupported by client",
			RequestID: requestID,
			Type:      "error",
		}
		writeSSEMessage(w, flusher, chunk)
		return
	}

	llm, err := openai.New(
		openai.WithBaseURL(receiver.conf.Openai.BaseUrl),
		openai.WithToken(lo.Ternary(stringutils.IsNotEmpty(receiver.conf.Openai.Token), receiver.conf.Openai.Token, os.Getenv("OPENAI_API_KEY"))),
		openai.WithEmbeddingModel(receiver.conf.Openai.EmbeddingModel),
		openai.WithModel(receiver.conf.Openai.Model),
	)
	if err != nil {
		zlogger.Error().Err(err).Msgf("Create LLM failed, requestId: %s", requestID)
		chunk := dto.ChatResponse{
			Content:   err.Error(),
			RequestID: requestID,
			Type:      "error",
		}
		writeSSEMessage(w, flusher, chunk)
		return
	}

	knowService := do.MustInvoke[know.ModuleKnowledge](nil)

	prompt := "请结合下面给出的上下文信息回答问题，答案必须分条阐述，力求条理清晰，如果不知道可以回答不知道，但不要编造答案：\n"

	if stringutils.IsEmpty(req.FileId) {
		queryResults, err := knowService.GetQuery(ctx, kdto.QueryReq{
			Text:                req.Prompt,
			RetrieveLimit:       1000,
			SimilarityThreshold: 0.5,
		})
		if err != nil {
			zlogger.Error().Err(err).Msgf("Query knowledge base failed, requestId: %s", requestID)
			chunk := dto.ChatResponse{
				Content:   err.Error(),
				RequestID: requestID,
				Type:      "error",
			}
			writeSSEMessage(w, flusher, chunk)
			return err
		}

		if len(queryResults) == 0 {
			zlogger.Error().Msgf("Knowledge not found, requestId: %s", requestID)
			chunk := dto.ChatResponse{
				Content:   "非常抱歉，未能检索到相关信息，无法回答",
				RequestID: requestID,
				Type:      "error",
			}
			writeSSEMessage(w, flusher, chunk)
			return err
		}

		lo.ForEach(queryResults, func(item kdto.QueryResult, index int) {
			prompt += fmt.Sprintf("%d. %s\n", index+1, item.Content)
		})
	} else {
		listReq := kdto.GetListReq{
			FileId:      req.FileId,
			WithContent: true,
		}
		fileDTOList, _ := knowService.GetList(ctx, listReq)

		if len(fileDTOList) == 0 {
			zlogger.Error().Msgf("Knowledge not found, requestId: %s", requestID)
			chunk := dto.ChatResponse{
				Content:   "非常抱歉，未能检索到相关信息，无法回答",
				RequestID: requestID,
				Type:      "error",
			}
			writeSSEMessage(w, flusher, chunk)
			return err
		}

		lo.ForEach(fileDTOList, func(item kdto.FileDTO, index int) {
			prompt += fmt.Sprintf("%d. %s\n", index+1, item.Content)
		})
	}

	prompt += "请回答：" + req.Prompt + "\n\n\n"

	content := []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeSystem, "You are a senior public policy researcher."),
		llms.TextParts(llms.ChatMessageTypeHuman, prompt),
	}

	if _, err = llm.GenerateContent(ctx, content,
		llms.WithMaxTokens(4096),
		llms.WithTemperature(0.2),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			chunkResp := dto.ChatResponse{
				Content:   string(chunk),
				RequestID: requestID,
				Type:      "content",
			}
			return writeSSEMessage(w, flusher, chunkResp)
		})); err != nil {
		zlogger.Error().Err(err).Msgf("[%s] Error creating chat completion stream", requestID)
		chunk := dto.ChatResponse{
			Content:   "Failed to create chat completion stream",
			RequestID: requestID,
			Type:      "error",
		}
		writeSSEMessage(w, flusher, chunk)
		return
	}
	return
}

func writeSSEMessage(w http.ResponseWriter, flusher http.Flusher, chunk dto.ChatResponse) error {
	var err error
	chunkJSON, err := json.Marshal(chunk)
	if err != nil {
		return fmt.Errorf("error marshaling chunk: %v", err)
	}

	_, err = fmt.Fprintf(w, "data: %s\n\n", chunkJSON)
	//_, err = fmt.Fprint(w, chunk.Content)
	if err != nil {
		return fmt.Errorf("error writing to response: %v", err)
	}

	flusher.Flush()
	return nil
}
